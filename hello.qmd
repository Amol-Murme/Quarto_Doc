---
title: "ABC Bank Ltd."
execute:
   code-fold: true
   echo: false
subtitle: "Cognext model"
author: "XYZ"
date: "22-08-2022"
abstract: "You can produce a wide variety of output types from executable code blocks, including plots, tabular output from data frames, and plain text output (e.g. printing the results of statistical summaries)."
format:
  docx:
    toc: true
    number-sections: true
    highlight-style: github
jupyter: python3
---

## EXECUTIVE SUMMARY
  This document covers the model development process for **{{< var Algorithm.Model >}}** model. The model is a classification model that uses **{{< var Algorithm.Name >}}** with input data consisting of **{{< var.Algorithm.No_of_Observation >}}** observations and **{{< var Algorithm.Features >}}** features. The model achieves Auto of **{{< var Validation.Auto >}}** on validation dataset and **{{< var OOS_test.Auto >}}** on Out-of-Sample (OOS) test dataset.

## MODEL PERFORMANCE SUMMARY
  | Dataset     |   Size                      |      Auto                   |
  |-------------|-----|------|
  | Validation  | {{< var Validation.Size >}} | {{< var Validation.Auto >}} |
  | OSS Test    | {{< var OOS_test.Size >}}   | {{< var OOS_test.Auto >}}   |

## DATASET
  Following dataset were used for model training, tuning and OOS performance estimation:

  | Dataset   |   Size       |   Features  | Purpose    |
  |-----------|--------------|-------------|------------|
  | Train     | {{< var Train.Size >}} | {{< var Train.Features >}} |{{< var Train.Purpose >}} |
  |Validation |{{< var Validation.Size >}}|{{< var Validation.Features >}}|{{< var Validation.Purpose >}}|
  | OSS Test  |{{< var OOS_test.Size >}}   | {{< var OOS_test.Features >}}|{{< var OOS_test.Purpose >}}|

## EDA
  Following is a summary of input data. Refer Annexure-1 for detailed EDA.
  

## Methodology Overview
  {{< var Algorithm.Name >}} is a fast and efficient implementation of gradient boosting algorithm. Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees.


```{python}
#| tags: [parameters]

alpha = 0.1
ratio = 0.1
import pandas as pd

df = pd.read_csv('Data source/test.csv')
#print(df.to_string(index= False))

from IPython.display import Markdown
from tabulate import tabulate
table = df.values.tolist()
Markdown(tabulate(
  table, 
  headers=df.columns,
  tablefmt= "grid"
))
```
 Following is a summary of steps performed to train the model:
 ![Model Development Pipeline](Images/MDP.png)

### Data Preparation
  The dataset is randomly split into train, validation and holdout test datasets. Train data is used for model fitting. Validation dataset is used for model tuning i.e. finding the optimal combination of hyperparameters that provide the best fit on a given dataset. Holdout test dataset is used to arrive at an unbiased estimate of OOS performance of the model.

### Feature Transformation
  Typically all features are converted into numeric features. This is a mandatory transformation for many algorithms such as XGBoost.

### Model Tuning
  Various models are fitted to the train dataset with multiple combination of hyperparameters (HP). These HP typically control model capacity (large capacity models will provide better fit on train data but may fail to generalize to OOS dataset), model complexity (typically models with larger capacity are also more complex) and model generalization (to prevent overfitting to train data).

### Model Performance Evaluation
  Performance of trained models is compared on validation dataset using different statistics. Final HP combination and the resultant final model is selected on basis of performance on the validation dataset.

### Model Stability
  Model stability is checked by detecting drift/shift in features between train, validation and test dataset. This is done by computing Stability Index at model and individual feature level to identify if model is stable or not.

## Model Details
  Detailed Information regarding model.

### Model Hyperparameters
  Following is a summary of key model hyperparameters:
```{python}
  import pandas as pd
  df1 = pd.read_csv('Data source/test.csv')

  from IPython.display import Markdown
  from tabulate import tabulate
  table = df1.values.tolist()
  Markdown(tabulate(
    table, 
    headers=df1.columns,
    tablefmt= "grid"
  ))
```

### Important Features
  Following is a list of important features for the model:
    
  | Dataset     |   Size                      |      Auto                   |
  |-------------|-----------------------------|-----------------------------|
  | Validation  | {{< var Validation.Size >}} | {{< var Validation.Auto >}} |
  | OSS Test    | {{< var OOS_test.Size >}}   | {{< var OOS_test.Auto >}}   |

  ![Partial Dependance Graph](Images/PDP.png)

### Model Performance
  Following are the model performance statistics on validation and OOS test dataset:
  **Validation dataset**

  ![Model Performance on Validation dataset](Images/Performance_test_val.png)

  **Test dataset**

  ![Model Performance on Test dataset](Images/performance_test.png)

### Model Stability
  Following are model stability statistics:
  **Train vs. Validation dataset**
  ![Model Stability (Val vs. Train dataset)](Images/roc.png)

  **Validation vs. Test dataset**
  ![Model Stability (Val vs. Test dataset)](Images/roc.png)

### Model Performance by Number of Features
  Following is a summary of model performance, if it is replaced with a model with subset of important features. This may be used to identify if final modelâ€™s performance maybe matched with a simpler model with less number of features.