Algorithm_Features: '70'
Algorithm_Model: XGBoost_2_AutoML_20210218_195405
Algorithm_Name: XGBoost
Algorithm_No_of_Observation: '20000'
Feature_Transformation: Typically all features are converted into numeric features.
  This is a mandatory transformation for many algorithms such as XGBoost.
Headings_h1: EXECUTIVE SUMMARY
Headings_h2: MODEL PERFORMANCE SUMMARY
Headings_h3: DATASET
Headings_h4: EDA
Headings_h5: Methodology Overview
Headings_h5_1: Data Preparation
Headings_h5_2: Feature Transformation
Headings_h5_3: Model Tuning
Headings_h5_4: Model Performance Evaluation
Headings_h5_5: Model Stability
Headings_h6: Model Details
Headings_h6_1: Model Hyperparameters
Headings_h6_2: Important Features
Headings_h6_3: Model Performance
Headings_h6_4: Model Stability Statistics
Headings_h6_5: Model Scoring History 213zzzzzzz
Model_Details_details: Detailed Information regarding model.
Model_Perfor_Eval: Performance of trained models is compared on validation dataset
  using different statistics. Final HP combination and the resultant final model is
  selected on basis of performance on the validation dataset.
Model_Stability: Model stability is checked by detecting drift/shift in features between
  train, validation and test dataset. This is done by computing Stability Index at
  model and individual feature level to identify if model is stable or not.
Model_Tunning: Various models are fitted to the train dataset with multiple combination
  of hyperparameters (HP). These HP typically control model capacity (large capacity
  models will provide better fit on train data but may fail to generalize to OOS dataset),
  model complexity (typically models with larger capacity are also more complex) and
  model generalization (to prevent overfitting to train data).
OOS_test_Auto: 74.98%
Validation_Auto: 75.84%
